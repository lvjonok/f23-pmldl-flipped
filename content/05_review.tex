\section{Review of latest works}

\begin{frame}
    \frametitle{OPIRL: Sample Efficient Off-Policy Inverse Reinforcement Learning via Distribution Matching \cite{hoshino_opirl_2022}}

    \begin{center}
        \includegraphics[width=0.4\linewidth]{content/images/oripl/im1.png}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{OPIRL: Sample Efficient Off-Policy Inverse Reinforcement Learning via Distribution Matching \cite{hoshino_opirl_2022}}

    \begin{center}
        \includegraphics[width=0.55\linewidth]{content/images/oripl/im2.png}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{{DriveIRL}: {Drive} in {Real} {Life} with {Inverse} {Reinforcement} {Learning} \cite{phan-minh_driveirl_2023}}

    \begin{center}
        \includegraphics[width=0.55\linewidth]{content/images/driveirl.png}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Human-{Guided} {Motion} {Planning} in {Partially} {Observable} {Environments} \cite{quintero-pena_human-guided_2022}}

    \begin{center}
        \includegraphics[width=0.55\linewidth]{content/images/human_guided.png}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Inverse {Reinforcement} {Learning} {Framework} for {Transferring} {Task} {Sequencing} {Policies} from {Humans} to {Robots} in {Manufacturing} {Applications} \cite{manyar_inverse_2023}}

    \begin{center}
        \includegraphics[width=0.7\linewidth]{content/images/inversereinforce.png}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Online Prediction of Lane Change with a Hierarchical Learning-Based Approach \cite{liao_online_2022}}

    \begin{center}
        \includegraphics[width=0.6\linewidth]{content/images/lanechange.png}
    \end{center}
\end{frame}

\begin{frame}
    \frametitle{Personalized Car Following for Autonomous Driving with Inverse Reinforcement Learning \cite{zhao_personalized_2022}}

    \begin{center}
        \includegraphics[width=0.35\linewidth]{content/images/personalized_car.png}
    \end{center}
\end{frame}